## kubeadm-highavailiability - åŸºäºkubeadmçš„kubernetesé«˜å¯ç”¨é›†ç¾¤éƒ¨ç½²ï¼Œæ”¯æŒv1.9.xå’Œv1.7.xç‰ˆæœ¬ä»¥åŠv1.6.xç‰ˆæœ¬



![k8s logo](images/v1.6-v1.7/Kubernetes.png)

- [ä¸­æ–‡æ–‡æ¡£(for v1.9.xç‰ˆæœ¬)](README_CN.md)
- [English document(for v1.9.x version)](README.md)
- [ä¸­æ–‡æ–‡æ¡£(for v1.7.xç‰ˆæœ¬)](v1.6-v1.7/README_CN.md)
- [English document(for v1.7.x version)](v1.6-v1.7/README.md)
- [ä¸­æ–‡æ–‡æ¡£(for v1.6.xç‰ˆæœ¬)](v1.6-v1.7/README_v1.6.x_CN.md)
- [English document(for v1.6.x version)](v1.6-v1.7/README_v1.6.x.md)

---

- [GitHubé¡¹ç›®åœ°å€](https://github.com/cookeem/kubeadm-ha/)
- [OSChinaé¡¹ç›®åœ°å€](https://git.oschina.net/cookeem/kubeadm-ha/)

---

- è¯¥æŒ‡å¼•é€‚ç”¨äºv1.9.xç‰ˆæœ¬çš„kubernetesé›†ç¾¤

> v1.9.0ä»¥å‰çš„ç‰ˆæœ¬kubeadmè¿˜ä¸æ”¯æŒé«˜å¯ç”¨éƒ¨ç½²ï¼Œå› æ­¤ä¸æ¨èä½œä¸ºç”Ÿäº§ç¯å¢ƒçš„éƒ¨ç½²æ–¹å¼ã€‚ä»v1.9.xç‰ˆæœ¬å¼€å§‹ï¼Œkubeadmå®˜æ–¹æ­£å¼æ”¯æŒé«˜å¯ç”¨é›†ç¾¤çš„éƒ¨ç½²ï¼Œå®‰è£…kubeadmåŠ¡å¿…ä¿è¯ç‰ˆæœ¬è‡³å°‘ä¸º1.9.0ã€‚

### ç›®å½•

1. [éƒ¨ç½²æ¶æ„](#éƒ¨ç½²æ¶æ„)
    1. [æ¦‚è¦éƒ¨ç½²æ¶æ„](#æ¦‚è¦éƒ¨ç½²æ¶æ„)
    1. [è¯¦ç»†éƒ¨ç½²æ¶æ„](#è¯¦ç»†éƒ¨ç½²æ¶æ„)
    1. [ä¸»æœºèŠ‚ç‚¹æ¸…å•](#ä¸»æœºèŠ‚ç‚¹æ¸…å•)
1. [å®‰è£…å‰å‡†å¤‡](#å®‰è£…å‰å‡†å¤‡)
    1. [ç‰ˆæœ¬ä¿¡æ¯](#ç‰ˆæœ¬ä¿¡æ¯)
    1. [æ‰€éœ€dockeré•œåƒ](#æ‰€éœ€dockeré•œåƒ)
    1. [ç³»ç»Ÿè®¾ç½®](#ç³»ç»Ÿè®¾ç½®)
1. [kuberneteså®‰è£…](#kuberneteså®‰è£…)
    1. [firewalldå’Œiptablesç›¸å…³ç«¯å£è®¾ç½®](#firewalldå’Œiptablesç›¸å…³ç«¯å£è®¾ç½®)
    1. [kubernetesç›¸å…³æœåŠ¡å®‰è£…](#kubernetesç›¸å…³æœåŠ¡å®‰è£…)
1. [é…ç½®æ–‡ä»¶åˆå§‹åŒ–](#é…ç½®æ–‡ä»¶åˆå§‹åŒ–)
    1. [åˆå§‹åŒ–è„šæœ¬é…ç½®](#åˆå§‹åŒ–è„šæœ¬é…ç½®) 
    1. [ç‹¬ç«‹etcdé›†ç¾¤éƒ¨ç½²](#ç‹¬ç«‹etcdé›†ç¾¤éƒ¨ç½²)
1. [ç¬¬ä¸€å°masteråˆå§‹åŒ–](#ç¬¬ä¸€å°masteråˆå§‹åŒ–)
    1. [kubeadmåˆå§‹åŒ–](#kubeadmåˆå§‹åŒ–)
    1. [å®‰è£…åŸºç¡€ç»„ä»¶](#å®‰è£…åŸºç¡€ç»„ä»¶)
1. [masteré›†ç¾¤é«˜å¯ç”¨è®¾ç½®](#masteré›†ç¾¤é«˜å¯ç”¨è®¾ç½®)
    1. [å¤åˆ¶é…ç½®](#å¤åˆ¶é…ç½®)
    1. [å…¶ä½™masterèŠ‚ç‚¹åˆå§‹åŒ–](#å…¶ä½™masterèŠ‚ç‚¹åˆå§‹åŒ–)
    1. [keepalivedå®‰è£…é…ç½®](#keepalivedå®‰è£…é…ç½®)
    1. [nginxè´Ÿè½½å‡è¡¡é…ç½®](#nginxè´Ÿè½½å‡è¡¡é…ç½®)
    1. [kube-proxyé…ç½®](#kube-proxyé…ç½®)
1. [nodeèŠ‚ç‚¹åŠ å…¥é«˜å¯ç”¨é›†ç¾¤è®¾ç½®](#nodeèŠ‚ç‚¹åŠ å…¥é«˜å¯ç”¨é›†ç¾¤è®¾ç½®)
    1. [kubeadmåŠ å…¥é«˜å¯ç”¨é›†ç¾¤](#kubeadmåŠ å…¥é«˜å¯ç”¨é›†ç¾¤)
    1. [éªŒè¯é›†ç¾¤é«˜å¯ç”¨è®¾ç½®](#éªŒè¯é›†ç¾¤é«˜å¯ç”¨è®¾ç½®)


### éƒ¨ç½²æ¶æ„

#### æ¦‚è¦éƒ¨ç½²æ¶æ„

![ha logo](images/v1.6-v1.7/ha.png)

* kubernetesé«˜å¯ç”¨çš„æ ¸å¿ƒæ¶æ„æ˜¯masterçš„é«˜å¯ç”¨ï¼Œkubectlã€å®¢æˆ·ç«¯ä»¥åŠnodesè®¿é—®load balancerå®ç°é«˜å¯ç”¨ã€‚

---
[è¿”å›ç›®å½•](#ç›®å½•)

#### è¯¦ç»†éƒ¨ç½²æ¶æ„

![k8s ha](images/v1.6-v1.7/k8s-ha.png)

* kubernetesç»„ä»¶è¯´æ˜

> kube-apiserverï¼šé›†ç¾¤æ ¸å¿ƒï¼Œé›†ç¾¤APIæ¥å£ã€é›†ç¾¤å„ä¸ªç»„ä»¶é€šä¿¡çš„ä¸­æ¢ï¼›é›†ç¾¤å®‰å…¨æ§åˆ¶ï¼›

> etcdï¼šé›†ç¾¤çš„æ•°æ®ä¸­å¿ƒï¼Œç”¨äºå­˜æ”¾é›†ç¾¤çš„é…ç½®ä»¥åŠçŠ¶æ€ä¿¡æ¯ï¼Œéå¸¸é‡è¦ï¼Œå¦‚æœæ•°æ®ä¸¢å¤±é‚£ä¹ˆé›†ç¾¤å°†æ— æ³•æ¢å¤ï¼›å› æ­¤é«˜å¯ç”¨é›†ç¾¤éƒ¨ç½²é¦–å…ˆå°±æ˜¯etcdæ˜¯é«˜å¯ç”¨é›†ç¾¤ï¼›

> kube-schedulerï¼šé›†ç¾¤Podçš„è°ƒåº¦ä¸­å¿ƒï¼›é»˜è®¤kubeadmå®‰è£…æƒ…å†µä¸‹--leader-electå‚æ•°å·²ç»è®¾ç½®ä¸ºtrueï¼Œä¿è¯masteré›†ç¾¤ä¸­åªæœ‰ä¸€ä¸ªkube-schedulerå¤„äºæ´»è·ƒçŠ¶æ€ï¼›

> kube-controller-managerï¼šé›†ç¾¤çŠ¶æ€ç®¡ç†å™¨ï¼Œå½“é›†ç¾¤çŠ¶æ€ä¸æœŸæœ›ä¸åŒæ—¶ï¼Œkcmä¼šåŠªåŠ›è®©é›†ç¾¤æ¢å¤æœŸæœ›çŠ¶æ€ï¼Œæ¯”å¦‚ï¼šå½“ä¸€ä¸ªpodæ­»æ‰ï¼Œkcmä¼šåŠªåŠ›æ–°å»ºä¸€ä¸ªpodæ¥æ¢å¤å¯¹åº”replicas setæœŸæœ›çš„çŠ¶æ€ï¼›é»˜è®¤kubeadmå®‰è£…æƒ…å†µä¸‹--leader-electå‚æ•°å·²ç»è®¾ç½®ä¸ºtrueï¼Œä¿è¯masteré›†ç¾¤ä¸­åªæœ‰ä¸€ä¸ªkube-controller-managerå¤„äºæ´»è·ƒçŠ¶æ€ï¼›

> kubelet: kubernetes node agentï¼Œè´Ÿè´£ä¸nodeä¸Šçš„docker engineæ‰“äº¤é“ï¼›

> kube-proxy: æ¯ä¸ªnodeä¸Šä¸€ä¸ªï¼Œè´Ÿè´£service vipåˆ°endpoint podçš„æµé‡è½¬å‘ï¼Œå½“å‰ä¸»è¦é€šè¿‡è®¾ç½®iptablesè§„åˆ™å®ç°ã€‚

* è´Ÿè½½å‡è¡¡

> keepalivedé›†ç¾¤è®¾ç½®ä¸€ä¸ªè™šæ‹Ÿipåœ°å€ï¼Œè™šæ‹Ÿipåœ°å€æŒ‡å‘devops-master01ã€devops-master02ã€devops-master03ã€‚

> nginxç”¨äºdevops-master01ã€devops-master02ã€devops-master03çš„apiserverçš„è´Ÿè½½å‡è¡¡ã€‚å¤–éƒ¨kubectlä»¥åŠnodesè®¿é—®apiserverçš„æ—¶å€™å°±å¯ä»¥ç”¨è¿‡keepalivedçš„è™šæ‹Ÿip(192.168.20.10)ä»¥åŠnginxç«¯å£(16443)è®¿é—®masteré›†ç¾¤çš„apiserverã€‚

---

[è¿”å›ç›®å½•](#ç›®å½•)

#### ä¸»æœºèŠ‚ç‚¹æ¸…å•

ä¸»æœºå | IPåœ°å€ | è¯´æ˜ | ç»„ä»¶ 
:--- | :--- | :--- | :---
devops-master01 ~ 03 | 192.168.66.100 ~ 102 | masterèŠ‚ç‚¹ * 3 | keepalivedã€nginxã€etcdã€kubeletã€kube-apiserverã€kube-schedulerã€kube-proxyã€kube-dashboardã€heapsterã€calico
æ—  | 192.168.66.10 | keepalivedè™šæ‹ŸIP | æ— 
devops-node01 ~ 02 | 192.168.66.103 ~ 104 | nodeèŠ‚ç‚¹ * 2 | kubeletã€kube-proxy

---

[è¿”å›ç›®å½•](#ç›®å½•)

### å®‰è£…å‰å‡†å¤‡

#### ç‰ˆæœ¬ä¿¡æ¯

* Linuxç‰ˆæœ¬ï¼šCentOS 7.4.1708
* å†…æ ¸ç‰ˆæœ¬: 4.6.4-1.el7.elrepo.x86_64


```
$ cat /etc/redhat-release 
CentOS Linux release 7.4.1708 (Core) 

$ uname -r
4.6.4-1.el7.elrepo.x86_64
```

* dockerç‰ˆæœ¬ï¼š17.12.0-ce-rc2

```
$ docker version
Client:
 Version:   17.12.0-ce-rc2
 API version:   1.35
 Go version:    go1.9.2
 Git commit:    f9cde63
 Built: Tue Dec 12 06:42:20 2017
 OS/Arch:   linux/amd64

Server:
 Engine:
  Version:  17.12.0-ce-rc2
  API version:  1.35 (minimum version 1.12)
  Go version:   go1.9.2
  Git commit:   f9cde63
  Built:    Tue Dec 12 06:44:50 2017
  OS/Arch:  linux/amd64
  Experimental: false
```

* kubeadmç‰ˆæœ¬ï¼šv1.9.3

```
$ kubeadm version
kubeadm version: &version.Info{Major:"1", Minor:"9", GitVersion:"v1.9.3", GitCommit:"d2835416544f298c919e2ead3be3d0864b52323b", GitTreeState:"clean", BuildDate:"2018-02-07T11:55:20Z", GoVersion:"go1.9.2", Compiler:"gc", Platform:"linux/amd64"}
```

* kubeletç‰ˆæœ¬ï¼šv1.9.3

```
$ kubelet --version
Kubernetes v1.9.3
```

* ç½‘ç»œç»„ä»¶

> canal (flannel + calico)

---

[è¿”å›ç›®å½•](#ç›®å½•)

#### æ‰€éœ€dockeré•œåƒ

* ç›¸å…³dockeré•œåƒä»¥åŠç‰ˆæœ¬

```
# kuberentes basic components
docker pull gcr.io/google_containers/kube-apiserver-amd64:v1.9.3
docker pull gcr.io/google_containers/kube-proxy-amd64:v1.9.3
docker pull gcr.io/google_containers/kube-scheduler-amd64:v1.9.3
docker pull gcr.io/google_containers/kube-controller-manager-amd64:v1.9.3
docker pull gcr.io/google_containers/k8s-dns-sidecar-amd64:1.14.7
docker pull gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.14.7
docker pull gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.7
docker pull gcr.io/google_containers/etcd-amd64:3.1.10
docker pull gcr.io/google_containers/pause-amd64:3.0

# kubernetes networks add ons
docker pull quay.io/coreos/flannel:v0.9.1-amd64
docker pull quay.io/calico/node:v3.0.3
docker pull quay.io/calico/kube-controllers:v2.0.1
docker pull quay.io/calico/cni:v2.0.1

# kubernetes dashboard
docker pull gcr.io/google_containers/kubernetes-dashboard-amd64:v1.8.3

# kubernetes heapster
docker pull gcr.io/google_containers/heapster-influxdb-amd64:v1.3.3
docker pull gcr.io/google_containers/heapster-grafana-amd64:v4.4.3
docker pull gcr.io/google_containers/heapster-amd64:v1.4.2

# kubernetes apiserver load balancer
docker pull nginx:latest
```

---

[è¿”å›ç›®å½•](#ç›®å½•)

#### ç³»ç»Ÿè®¾ç½®

ä¸»æœºåç§°è®¾ç½®

```shell
hostnamectl --static set-hostname master01
hostnamectl --static set-hostname master02
hostnamectl --static set-hostname master03
hostnamectl --static set-hostname node01
hostnamectl --static set-hostname node02

cat >> /etc/hosts <<EOF
192.168.66.100 master01 etcd-host1
192.168.66.101 master02 etcd-host2
192.168.66.102 master03 etcd-host3
192.168.66.104 node01
192.168.66.105 node02
192.168.66.106 node03
EOF
```

* åœ¨æ‰€æœ‰kubernetesèŠ‚ç‚¹ä¸Šå¢åŠ kubernetesä»“åº“ 

```
$ cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
EOF
```

* åœ¨æ‰€æœ‰kubernetesèŠ‚ç‚¹ä¸Šè¿›è¡Œç³»ç»Ÿæ›´æ–°

```shell
$ yum update -y
```

* åœ¨æ‰€æœ‰kubernetesèŠ‚ç‚¹ä¸Šè®¾ç½®SELINUXä¸ºpermissiveæ¨¡å¼

```shell
# ç¦ç”¨SELinux, ç›®çš„æ˜¯è®©å®¹å™¨å¯ä»¥è¯»å–ä¸»æœºçš„æ–‡ä»¶ç³»ç»Ÿ.
setenforce 0
sed -i "s/^SELINUX=enforcing/SELINUX=permissive/g" /etc/sysconfig/selinux 
sed -i "s/^SELINUX=enforcing/SELINUX=permissive/g" /etc/selinux/config 
```

* åœ¨æ‰€æœ‰kubernetesèŠ‚ç‚¹ä¸Šè®¾ç½®iptableså‚æ•°ï¼Œå¦åˆ™kubeadm initä¼šæç¤ºé”™è¯¯

```shell
cat <<EOF >  /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
EOF

sysctl --system
```

* åœ¨æ‰€æœ‰kubernetesèŠ‚ç‚¹ä¸Šç¦ç”¨swap

```shell
#å…³é—­swap(è²Œä¼¼åªæœ‰1.8ä»¥ä¸Šéœ€è¦æ“ä½œ,å¾…ç¡®è®¤)
swapoff -a
#å†æŠŠ/etc/fstabæ–‡ä»¶ä¸­å¸¦æœ‰swapçš„è¡Œåˆ äº†,æ²¡æœ‰å°±æ— è§†
sed -i '/swap/'d /etc/fstab

# ç¡®è®¤swapå·²ç»è¢«ç¦ç”¨
cat /proc/swaps
Filename                Type        Size    Used    Priority
```

* åœ¨æ‰€æœ‰kubernetesèŠ‚ç‚¹ä¸Šé‡å¯ä¸»æœº

```
reboot
```

---

[è¿”å›ç›®å½•](#ç›®å½•)

### kuberneteså®‰è£…

#### firewalldå’Œiptablesç›¸å…³ç«¯å£è®¾ç½®

#####ç›¸å…³ç«¯å£ï¼ˆmasterï¼‰

åè®® | æ–¹å‘ | ç«¯å£ | è¯´æ˜
:--- | :--- | :--- | :---
TCP | Inbound | 16443*    | Load balancer Kubernetes API server port
TCP | Inbound | 6443     | Kubernetes API server
TCP | Inbound | 4001      | etcd listen client port
TCP | Inbound | 2379-2380 | etcd server client API
TCP | Inbound | 10250     | Kubelet API
TCP | Inbound | 10251     | kube-scheduler
TCP | Inbound | 10252     | kube-controller-manager
TCP | Inbound | 10255     | Read-only Kubelet API
TCP | Inbound | 30000-32767 | NodePort Services

#####åœ¨æ‰€æœ‰masterèŠ‚ç‚¹ä¸Šå¼€æ”¾ç›¸å…³firewalldç«¯å£

åœ¨æ‰€æœ‰masterèŠ‚ç‚¹ä¸Šå¼€æ”¾ç›¸å…³firewalldç«¯å£ï¼ˆå› ä¸ºä»¥ä¸ŠæœåŠ¡åŸºäºdockeréƒ¨ç½²ï¼Œå¦‚æœdockerç‰ˆæœ¬ä¸º17.xï¼Œå¯ä»¥ä¸è¿›è¡Œä»¥ä¸‹è®¾ç½®ï¼Œå› ä¸ºdockerä¼šè‡ªåŠ¨ä¿®æ”¹iptablesæ·»åŠ ç›¸å…³ç«¯å£ï¼‰

```shell
systemctl status firewalld

firewall-cmd --zone=public --add-port=16443/tcp --permanent
firewall-cmd --zone=public --add-port=6443/tcp --permanent
firewall-cmd --zone=public --add-port=4001/tcp --permanent
firewall-cmd --zone=public --add-port=2379-2380/tcp --permanent
firewall-cmd --zone=public --add-port=10250/tcp --permanent
firewall-cmd --zone=public --add-port=10251/tcp --permanent
firewall-cmd --zone=public --add-port=10252/tcp --permanent
firewall-cmd --zone=public --add-port=10255/tcp --permanent
firewall-cmd --zone=public --add-port=30000-32767/tcp --permanent

firewall-cmd --reload

firewall-cmd --list-all --zone=public

```

```properties
public (active)
  target: default
  icmp-block-inversion: no
  interfaces: ens2f1 ens1f0 nm-bond
  sources: 
  services: ssh dhcpv6-client
  ports: 4001/tcp 6443/tcp 2379-2380/tcp 10250/tcp 10251/tcp 10252/tcp 10255/tcp 30000-32767/tcp
  protocols: 
  masquerade: no
  forward-ports: 
  source-ports: 
  icmp-blocks: 
  rich rules: 
```



#####ç›¸å…³ç«¯å£ï¼ˆworkerï¼‰

åè®® | æ–¹å‘ | ç«¯å£ | è¯´æ˜
:--- | :--- | :--- | :---
TCP | Inbound | 10250       | Kubelet API
TCP | Inbound | 10255       | Read-only Kubelet API
TCP | Inbound | 30000-32767 | NodePort Services

#####æ‰€æœ‰workerèŠ‚ç‚¹ä¸Šå¼€æ”¾ç›¸å…³firewalldç«¯å£

åœ¨æ‰€æœ‰workerèŠ‚ç‚¹ä¸Šå¼€æ”¾ç›¸å…³firewalldç«¯å£ï¼ˆå› ä¸ºä»¥ä¸ŠæœåŠ¡åŸºäºdockeréƒ¨ç½²ï¼Œå¦‚æœdockerç‰ˆæœ¬ä¸º17.xï¼Œå¯ä»¥ä¸è¿›è¡Œä»¥ä¸‹è®¾ç½®ï¼Œå› ä¸ºdockerä¼šè‡ªåŠ¨ä¿®æ”¹iptablesæ·»åŠ ç›¸å…³ç«¯å£ï¼‰

```
systemctl status firewalld

firewall-cmd --zone=public --add-port=10250/tcp --permanent
firewall-cmd --zone=public --add-port=10255/tcp --permanent
firewall-cmd --zone=public --add-port=30000-32767/tcp --permanent

firewall-cmd --reload

firewall-cmd --list-all --zone=public
```

```properties
public (active)
  target: default
  icmp-block-inversion: no
  interfaces: ens2f1 ens1f0 nm-bond
  sources: 
  services: ssh dhcpv6-client
  ports: 10250/tcp 10255/tcp 30000-32767/tcp
  protocols: 
  masquerade: no
  forward-ports: 
  source-ports: 
  icmp-blocks: 
  rich rules: 
```



#####åœ¨æ‰€æœ‰kubernetesèŠ‚ç‚¹ä¸Šå…è®¸kube-proxyçš„forward

```shell
firewall-cmd --permanent --direct --add-rule ipv4 filter INPUT 1 -i docker0 -j ACCEPT -m comment --comment "kube-proxy redirects"
firewall-cmd --permanent --direct --add-rule ipv4 filter FORWARD 1 -o docker0 -j ACCEPT -m comment --comment "docker subnet"
firewall-cmd --permanent --direct --add-rule ipv4 filter FORWARD 1 -i flannel.1 -j ACCEPT -m comment --comment "flannel subnet"
firewall-cmd --permanent --direct --add-rule ipv4 filter FORWARD 1 -o flannel.1 -j ACCEPT -m comment --comment "flannel subnet"
firewall-cmd --reload


firewall-cmd --direct --get-all-rules

ipv4 filter INPUT 1 -i docker0 -j ACCEPT -m comment --comment 'kube-proxy redirects'
ipv4 filter FORWARD 1 -o docker0 -j ACCEPT -m comment --comment 'docker subnet'
ipv4 filter FORWARD 1 -i flannel.1 -j ACCEPT -m comment --comment 'flannel subnet'
ipv4 filter FORWARD 1 -o flannel.1 -j ACCEPT -m comment --comment 'flannel subnet'
```

- åœ¨æ‰€æœ‰kubernetesèŠ‚ç‚¹ä¸Šï¼Œåˆ é™¤iptablesçš„è®¾ç½®ï¼Œè§£å†³kube-proxyæ— æ³•å¯ç”¨nodePortã€‚ï¼ˆæ³¨æ„ï¼šæ¯æ¬¡é‡å¯firewalldå¿…é¡»æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼‰

```shell
iptables -D INPUT -j REJECT --reject-with icmp-host-prohibited
```

---

[è¿”å›ç›®å½•](#ç›®å½•)

#### kubernetesç›¸å…³æœåŠ¡å®‰è£…

* åœ¨æ‰€æœ‰kubernetesèŠ‚ç‚¹ä¸ŠéªŒè¯SELINUXæ¨¡å¼ï¼Œå¿…é¡»ä¿è¯SELINUXä¸ºpermissiveæ¨¡å¼ï¼Œå¦åˆ™kuberneteså¯åŠ¨ä¼šå‡ºç°å„ç§å¼‚å¸¸

```
$ getenforce
Permissive
```

#####å®‰è£…docker,docker-compose,k8s,

åœ¨æ‰€æœ‰kubernetesèŠ‚ç‚¹ä¸Šå®‰è£…å¹¶å¯åŠ¨kubernetes 

```shell
 yum -y install docker-ce-17.12.1.ce-1.el7.centos
curl -L https://github.com/docker/compose/releases/download/1.17.1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose
chmod +x /usr/local/bin/docker-compose
docker-compose --version

systemctl enable docker && systemctl start docker && systemctl status docker

cd kubeadm-rpm && rpm -ivh *.rpm
systemctl enable kubelet && systemctl start kubelet

```

#####é…ç½®kubectl

```properties
# é…ç½®kubectl
#kubelet ä¿®æ”¹ é…ç½®ä»¥ä½¿ç”¨æœ¬åœ°è‡ªå®šä¹‰pauseé•œåƒ
export KUBE_REPO_PREFIX=registry.cn-beijing.aliyuncs.com/k8s_len
export KUBE_PAUSE_IMAGE=${KUBE_REPO_PREFIX}/pause-amd64:3.0
cat > /etc/systemd/system/kubelet.service.d/20-pod-infra-image.conf <<EOF
[Service]
Environment="KUBELET_EXTRA_ARGS=--pod-infra-container-image=${KUBE_PAUSE_IMAGE}"
EOF
systemctl daemon-reload && systemctl enable kubelet && systemctl restart kubelet && systemctl status kubelet
```

#####åœ¨æ‰€æœ‰kubernetesèŠ‚ç‚¹ä¸Šè®¾ç½®kubeletä½¿ç”¨cgroupfs

åœ¨æ‰€æœ‰kubernetesèŠ‚ç‚¹ä¸Šè®¾ç½®kubeletä½¿ç”¨cgroupfsï¼Œä¸dockerdä¿æŒä¸€è‡´ï¼Œå¦åˆ™kubeletä¼šå¯åŠ¨æŠ¥é”™

```shell
# é»˜è®¤kubeletä½¿ç”¨çš„cgroup-driver=systemdï¼Œæ”¹ä¸ºcgroup-driver=cgroupfs
# vi /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
#Environment="KUBELET_CGROUP_ARGS=--cgroup-driver=systemd"
#Environment="KUBELET_CGROUP_ARGS=--cgroup-driver=cgroupfs"
sed  -i 's/--cgroup-driver=systemd/--cgroup-driver=cgroupfs/' /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
# é‡è®¾kubeletæœåŠ¡ï¼Œå¹¶é‡å¯kubeletæœåŠ¡
$ systemctl daemon-reload && systemctl restart kubelet && systemctl status kubelet
```

#####åœ¨æ‰€æœ‰masterèŠ‚ç‚¹ä¸Šå®‰è£…å¹¶å¯åŠ¨keepalived

```shell
yum install -y keepalived
systemctl enable keepalived && systemctl restart keepalived && systemctl status keepalived
```

---

[è¿”å›ç›®å½•](#ç›®å½•)

### é…ç½®æ–‡ä»¶åˆå§‹åŒ–

#### åˆå§‹åŒ–è„šæœ¬é…ç½®

* åœ¨æ‰€æœ‰masterèŠ‚ç‚¹ä¸Šè·å–ä»£ç ï¼Œå¹¶è¿›å…¥ä»£ç ç›®å½•

```shell
#git clone https://github.com/cookeem/kubeadm-ha
git clone https://github.com/len-2017/kubeadm-ha.git
cd kubeadm-ha
git checkout len_v1.9.3 
```

* åœ¨æ‰€æœ‰masterèŠ‚ç‚¹ä¸Šè®¾ç½®åˆå§‹åŒ–è„šæœ¬é…ç½®ï¼Œæ¯ä¸€é¡¹é…ç½®å‚è§è„šæœ¬ä¸­çš„é…ç½®è¯´æ˜ï¼Œè¯·åŠ¡å¿…æ­£ç¡®é…ç½®ã€‚è¯¥è„šæœ¬ç”¨äºç”Ÿæˆç›¸å…³é‡è¦çš„é…ç½®æ–‡ä»¶

```shell
$ vi create-config.sh

#!/bin/bash

# local machine ip address
export K8SHA_IPLOCAL=192.168.66.100

# local machine etcd name, options: etcd1, etcd2, etcd3
export K8SHA_ETCDNAME=etcd1

# local machine keepalived state config, options: MASTER, BACKUP. One keepalived cluster only one MASTER, other's are BACKUP
export K8SHA_KA_STATE=MASTER

# local machine keepalived priority config, options: 102, 101, 100. MASTER must 102
export K8SHA_KA_PRIO=102

# local machine keepalived network interface name config, for example: eth0
export K8SHA_KA_INTF=ens34

#######################################
# all masters settings below must be same
#######################################

# master keepalived virtual ip address
export K8SHA_IPVIRTUAL=192.168.66.10

# master01 ip address
export K8SHA_IP1=192.168.66.100

# master02 ip address
export K8SHA_IP2=192.168.66.101

# master03 ip address
export K8SHA_IP3=192.168.66.102

# master01 hostname
export K8SHA_HOSTNAME1=master01

# master02 hostname
export K8SHA_HOSTNAME2=master02

# master03 hostname
export K8SHA_HOSTNAME3=master03

# keepalived auth_pass config, all masters must be same
export K8SHA_KA_AUTH=4cdf7dc3b4c90194d1600c483e10ad1d

# kubernetes cluster token, you can use 'kubeadm token generate' to get a new one
export K8SHA_TOKEN=7f276c.0741d82a5337f526

# kubernetes CIDR pod subnet, if CIDR pod subnet is "10.244.0.0/16" please set to "10.244.0.0\\/16"
export K8SHA_CIDR=10.244.0.0\\/16

# kubernetes CIDR service subnet, if CIDR service subnet is "10.96.0.0/12" please set to "10.96.0.0\\/12"
export K8SHA_SVC_CIDR=10.96.0.0\\/12

# calico network settings, set a reachable ip address for the cluster network interface, for example you can use the gateway ip address
export K8SHA_CALICO_REACHABLE_IP=192.168.66.1

##############################
# please do not modify anything below
##############################

# set etcd cluster docker-compose.yaml file
sed \
-e "s/K8SHA_ETCDNAME/$K8SHA_ETCDNAME/g" \
-e "s/K8SHA_IPLOCAL/$K8SHA_IPLOCAL/g" \
-e "s/K8SHA_IP1/$K8SHA_IP1/g" \
-e "s/K8SHA_IP2/$K8SHA_IP2/g" \
-e "s/K8SHA_IP3/$K8SHA_IP3/g" \
etcd/docker-compose.yaml.tpl > etcd/docker-compose.yaml

echo 'set etcd cluster docker-compose.yaml file success: etcd/docker-compose.yaml'

# set keepalived config file
mv /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak

cp keepalived/check_apiserver.sh /etc/keepalived/

sed \
-e "s/K8SHA_KA_STATE/$K8SHA_KA_STATE/g" \
-e "s/K8SHA_KA_INTF/$K8SHA_KA_INTF/g" \
-e "s/K8SHA_IPLOCAL/$K8SHA_IPLOCAL/g" \
-e "s/K8SHA_KA_PRIO/$K8SHA_KA_PRIO/g" \
-e "s/K8SHA_IPVIRTUAL/$K8SHA_IPVIRTUAL/g" \
-e "s/K8SHA_KA_AUTH/$K8SHA_KA_AUTH/g" \
keepalived/keepalived.conf.tpl > /etc/keepalived/keepalived.conf

echo 'set keepalived config file success: /etc/keepalived/keepalived.conf'

# set nginx load balancer config file
sed \
-e "s/K8SHA_IP1/$K8SHA_IP1/g" \
-e "s/K8SHA_IP2/$K8SHA_IP2/g" \
-e "s/K8SHA_IP3/$K8SHA_IP3/g" \
nginx-lb/nginx-lb.conf.tpl > nginx-lb/nginx-lb.conf

echo 'set nginx load balancer config file success: nginx-lb/nginx-lb.conf'

# set kubeadm init config file
sed \
-e "s/K8SHA_HOSTNAME1/$K8SHA_HOSTNAME1/g" \
-e "s/K8SHA_HOSTNAME2/$K8SHA_HOSTNAME2/g" \
-e "s/K8SHA_HOSTNAME3/$K8SHA_HOSTNAME3/g" \
-e "s/K8SHA_IP1/$K8SHA_IP1/g" \
-e "s/K8SHA_IP2/$K8SHA_IP2/g" \
-e "s/K8SHA_IP3/$K8SHA_IP3/g" \
-e "s/K8SHA_IPVIRTUAL/$K8SHA_IPVIRTUAL/g" \
-e "s/K8SHA_TOKEN/$K8SHA_TOKEN/g" \
-e "s/K8SHA_CIDR/$K8SHA_CIDR/g" \
-e "s/K8SHA_SVC_CIDR/$K8SHA_SVC_CIDR/g" \
kubeadm-init.yaml.tpl > kubeadm-init.yaml

echo 'set kubeadm init config file success: kubeadm-init.yaml'

# set canal deployment config file

sed \
-e "s/K8SHA_CIDR/$K8SHA_CIDR/g" \
-e "s/K8SHA_CALICO_REACHABLE_IP/$K8SHA_CALICO_REACHABLE_IP/g" \
kube-canal/canal.yaml.tpl > kube-canal/canal.yaml

echo 'set canal deployment config file success: kube-canal/canal.yaml'

```

* åœ¨æ‰€æœ‰masterèŠ‚ç‚¹ä¸Šè¿è¡Œé…ç½®è„šæœ¬ï¼Œåˆ›å»ºå¯¹åº”çš„é…ç½®æ–‡ä»¶ï¼Œé…ç½®æ–‡ä»¶åŒ…æ‹¬:

- etcdé›†ç¾¤docker-compose.yamlæ–‡ä»¶
- keepalivedé…ç½®æ–‡ä»¶
- nginxè´Ÿè½½å‡è¡¡é›†ç¾¤docker-compose.yamlæ–‡ä»¶
- kubeadm init é…ç½®æ–‡ä»¶
- canalé…ç½®æ–‡ä»¶

```shell
./create-config.sh
set etcd cluster docker-compose.yaml file success: etcd/docker-compose.yaml
set keepalived config file success: /etc/keepalived/keepalived.conf
set nginx load balancer config file success: nginx-lb/nginx-lb.conf
set kubeadm init config file success: kubeadm-init.yaml
set canal deployment config file success: kube-canal/canal.yaml
```

---

[è¿”å›ç›®å½•](#ç›®å½•)

#### ç‹¬ç«‹etcdé›†ç¾¤éƒ¨ç½²

* åœ¨æ‰€æœ‰masterèŠ‚ç‚¹ä¸Šé‡ç½®å¹¶å¯åŠ¨etcdé›†ç¾¤ï¼ˆéTLSæ¨¡å¼ï¼‰

```shell
# é‡ç½®kubernetesé›†ç¾¤
$ kubeadm reset

# æ¸…ç©ºetcdé›†ç¾¤æ•°æ®
$ rm -rf /var/lib/etcd-cluster

# é‡ç½®å¹¶å¯åŠ¨etcdé›†ç¾¤
docker-compose --file etcd/docker-compose.yaml stop
docker-compose --file etcd/docker-compose.yaml rm -f
docker-compose --file etcd/docker-compose.yaml up -d

# éªŒè¯etcdé›†ç¾¤çŠ¶æ€æ˜¯å¦æ­£å¸¸

docker exec -ti etcd etcdctl cluster-health
[root@master01 kubeadm-ha]# docker exec -ti etcd etcdctl cluster-health
member 472a2e811e55b95c is healthy: got healthy result from http://192.168.66.102:2379
member a3cef8b35b895bf6 is healthy: got healthy result from http://192.168.66.100:2379
member f29752f4343f3b79 is healthy: got healthy result from http://192.168.66.101:2379
cluster is healthy

docker exec -ti etcd etcdctl member list
472a2e811e55b95c: name=etcd3 peerURLs=http://192.168.66.102:2380 clientURLs=http://192.168.66.102:2379,http://192.168.66.102:4001 isLeader=true
a3cef8b35b895bf6: name=etcd1 peerURLs=http://192.168.66.100:2380 clientURLs=http://192.168.66.100:2379,http://192.168.66.100:4001 isLeader=false
f29752f4343f3b79: name=etcd2 peerURLs=http://192.168.66.101:2380 clientURLs=http://192.168.66.101:2379,http://192.168.66.101:4001 isLeader=false
```

---

[è¿”å›ç›®å½•](#ç›®å½•)

### ç¬¬ä¸€å°masteråˆå§‹åŒ–

#### kubeadmåˆå§‹åŒ–

* åœ¨æ‰€æœ‰masterèŠ‚ç‚¹ä¸Šé‡ç½®ç½‘ç»œ

```shell
systemctl stop kubelet
systemctl stop docker
rm -rf /var/lib/cni/
rm -rf /var/lib/kubelet/*
rm -rf /etc/cni/

åˆ é™¤é—ç•™çš„ç½‘ç»œæ¥å£
ip a | grep -E 'docker|flannel|cni'
ip link del docker0
ip link del flannel.1
ip link del cni0

systemctl restart docker && systemctl status docker
systemctl restart kubelet && systemctl status kubelet
ip a | grep -E 'docker|flannel|cni'
```

* åœ¨master01ä¸Šè¿›è¡Œåˆå§‹åŒ–ï¼Œæ³¨æ„ï¼ŒåŠ¡å¿…æŠŠè¾“å‡ºçš„kubeadm join --token XXX --discovery-token-ca-cert-hash YYY ä¿¡æ¯è®°å½•ä¸‹æ¥ï¼Œåç»­æ“ä½œéœ€è¦ç”¨åˆ°

```properties
kubeadm init --config=kubeadm-init.yaml
...
To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of machines by running the following on each node
as root:

  kubeadm join --token 7f276c.0741d82a5337f526 192.168.66.100:6443 --discovery-token-ca-cert-hash sha256:731e73e7a91afaac61b7f183cba840680b204ede71f30cce56c63bb12a112086
```

* åœ¨æ‰€æœ‰masterèŠ‚ç‚¹ä¸Šè®¾ç½®kubectlå®¢æˆ·ç«¯è¿æ¥

```shell
cat << EOF >> ~/.bashrc
export KUBECONFIG=/etc/kubernetes/admin.conf
EOF
source ~/.bashrc

æˆ–è€…æ‰§è¡Œ:
  #mkdir -p $HOME/.kube
  #sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  #sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

#### å®‰è£…åŸºç¡€ç»„ä»¶

#####åœ¨master01ä¸Šå®‰è£…flannelç½‘ç»œç»„ä»¶

```shell
# æ²¡æœ‰ç½‘ç»œç»„ä»¶çš„æƒ…å†µä¸‹ï¼ŒèŠ‚ç‚¹çŠ¶æ€æ˜¯ä¸æ­£å¸¸çš„
kubectl get node
NAME              STATUS    ROLES     AGE       VERSION
devops-master01   NotReady  master    14s       v1.9.1

# å®‰è£…canalç½‘ç»œç»„ä»¶
kubectl apply -f kube-canal/
configmap "canal-config" created
daemonset "canal" created
customresourcedefinition "felixconfigurations.crd.projectcalico.org" created
customresourcedefinition "bgpconfigurations.crd.projectcalico.org" created
customresourcedefinition "ippools.crd.projectcalico.org" created
customresourcedefinition "clusterinformations.crd.projectcalico.org" created
customresourcedefinition "globalnetworkpolicies.crd.projectcalico.org" created
customresourcedefinition "networkpolicies.crd.projectcalico.org" created
serviceaccount "canal" created
clusterrole "calico" created
clusterrole "flannel" created
clusterrolebinding "canal-flannel" created
clusterrolebinding "canal-calico" created

# ç­‰å¾…æ‰€æœ‰podsæ­£å¸¸
kubectl get pods --all-namespaces -o wide
NAMESPACE     NAME                                      READY     STATUS    RESTARTS   AGE       IP              NODE
kube-system   canal-hpn82                               3/3       Running   0          1m        192.168.20.27   devops-master01
kube-system   kube-apiserver-devops-master01            1/1       Running   0          1m        192.168.20.27   devops-master01
kube-system   kube-controller-manager-devops-master01   1/1       Running   0          50s       192.168.20.27   devops-master01
kube-system   kube-dns-6f4fd4bdf-vwbk8                  3/3       Running   0          1m        10.244.0.2      devops-master01
kube-system   kube-proxy-mr6l8                          1/1       Running   0          1m        192.168.20.27   devops-master01
kube-system   kube-scheduler-devops-master01            1/1       Running   0          57s       192.168.20.27   devops-master01
```

#####åœ¨devops-master01ä¸Šå®‰è£…dashboard

```shell
# è®¾ç½®masterèŠ‚ç‚¹ä¸ºschedulable
kubectl taint nodes --all node-role.kubernetes.io/master-

kubectl apply -f kube-dashboard/
serviceaccount "admin-user" created
clusterrolebinding "admin-user" created
secret "kubernetes-dashboard-certs" created
serviceaccount "kubernetes-dashboard" created
role "kubernetes-dashboard-minimal" created
rolebinding "kubernetes-dashboard-minimal" created
deployment "kubernetes-dashboard" created
service "kubernetes-dashboard" created
```

* é€šè¿‡æµè§ˆå™¨è®¿é—®dashboardåœ°å€

> https://192.168.66.100:30000/#!/login

* dashboardç™»å½•é¡µé¢æ•ˆæœå¦‚ä¸‹å›¾

![dashboard-login](images/dashboard-login.png)

* è·å–tokenï¼ŒæŠŠtokenç²˜è´´åˆ°loginé¡µé¢çš„tokenä¸­ï¼Œå³å¯è¿›å…¥dashboard

```shell
kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '{print $1}')
```

![dashboard](images/dashboard.png)

#####åœ¨devops-master01ä¸Šå®‰è£…heapster

```shell
#
kubectl apply -f kube-heapster/influxdb/
service "monitoring-grafana" created
serviceaccount "heapster" created
deployment "heapster" created
service "heapster" created
deployment "monitoring-influxdb" created
service "monitoring-influxdb" created

#
kubectl apply -f kube-heapster/rbac/
clusterrolebinding "heapster" created

#
kubectl get pods --all-namespaces 
NAMESPACE     NAME                                      READY     STATUS    RESTARTS   AGE
kube-system   canal-hpn82                               3/3       Running   0          6m
kube-system   heapster-65c5499476-gg2tk                 1/1       Running   0          2m
kube-system   kube-apiserver-devops-master01            1/1       Running   0          6m
kube-system   kube-controller-manager-devops-master01   1/1       Running   0          5m
kube-system   kube-dns-6f4fd4bdf-vwbk8                  3/3       Running   0          6m
kube-system   kube-proxy-mr6l8                          1/1       Running   0          6m
kube-system   kube-scheduler-devops-master01            1/1       Running   0          6m
kube-system   kubernetes-dashboard-7c7bfdd855-2slp2     1/1       Running   0          4m
kube-system   monitoring-grafana-6774f65b56-mwdjv       1/1       Running   0          2m
kube-system   monitoring-influxdb-59d57d4d58-xmrxk      1/1       Running   0          2m


# ç­‰å¾…5åˆ†é’Ÿ
$ kubectl top nodes
NAME              CPU(cores)   CPU%      MEMORY(bytes)   MEMORY%   
devops-master01   242m         0%        1690Mi          0%        
```

* è®¿é—®dashboardåœ°å€ï¼Œç­‰10åˆ†é’Ÿï¼Œå°±ä¼šæ˜¾ç¤ºæ€§èƒ½æ•°æ®

> https://192.168.66.100:30000/#!/login

![heapster-dashboard](images/heapster-dashboard.png)

![heapster](images/heapster.png)

* è‡³æ­¤ï¼Œç¬¬ä¸€å°masteræˆåŠŸå®‰è£…ï¼Œå¹¶å·²ç»å®Œæˆcanalã€dashboardã€heapsterçš„éƒ¨ç½²

---

[è¿”å›ç›®å½•](#ç›®å½•)

### masteré›†ç¾¤é«˜å¯ç”¨è®¾ç½®

#### å¤åˆ¶é…ç½®

* åœ¨master01ä¸Šå¤åˆ¶ç›®å½•/etc/kubernetes/pkiåˆ°devops-master02ã€devops-master03ï¼Œä»v1.9.xå¼€å§‹ï¼Œkubeadmä¼šæ£€æµ‹pkiç›®å½•æ˜¯å¦æœ‰è¯ä¹¦ï¼Œå¦‚æœå·²ç»å­˜åœ¨è¯ä¹¦åˆ™è·³è¿‡è¯ä¹¦ç”Ÿæˆçš„æ­¥éª¤

```shell
#
scp -r /etc/kubernetes/pki master02:/etc/kubernetes/
#
scp -r /etc/kubernetes/pki master03:/etc/kubernetes/

```

---
[è¿”å›ç›®å½•](#ç›®å½•)

#### å…¶ä½™masterèŠ‚ç‚¹åˆå§‹åŒ–

#####master02 åˆå§‹åŒ–

åœ¨master02è¿›è¡Œåˆå§‹åŒ–ï¼Œç­‰å¾…æ‰€æœ‰podsæ­£å¸¸å¯åŠ¨åå†è¿›è¡Œä¸‹ä¸€ä¸ªmasteråˆå§‹åŒ–ï¼Œ**ç‰¹åˆ«è¦ä¿è¯kube-apiserver-{current-node-name}å¤„äºrunningçŠ¶æ€**

```shell
# è¾“å‡ºçš„tokenå’Œdiscovery-token-ca-cert-hashåº”è¯¥ä¸devops-master01ä¸Šçš„å®Œå…¨ä¸€è‡´
$ kubeadm init --config=kubeadm-init.yaml
...
  kubeadm join --token 7f276c.0741d82a5337f526 192.168.66.101:6443 --discovery-token-ca-cert-hash sha256:731e73e7a91afaac61b7f183cba840680b204ede71f30cce56c63bb12a112086
```

#####master03åˆå§‹åŒ–

åœ¨devops-master03è¿›è¡Œåˆå§‹åŒ–ï¼Œç­‰å¾…æ‰€æœ‰podsæ­£å¸¸å¯åŠ¨åå†è¿›è¡Œä¸‹ä¸€ä¸ªmasteråˆå§‹åŒ–ï¼Œç‰¹åˆ«è¦ä¿è¯kube-apiserver-{current-node-name}å¤„äºrunningçŠ¶æ€

```shell
# è¾“å‡ºçš„tokenå’Œdiscovery-token-ca-cert-hashåº”è¯¥ä¸devops-master01ä¸Šçš„å®Œå…¨ä¸€è‡´
$ kubeadm init --config=kubeadm-init.yaml
...
  kubeadm join --token 7f276c.0741d82a5337f526 192.168.66.102:6443 --discovery-token-ca-cert-hash sha256:731e73e7a91afaac61b7f183cba840680b204ede71f30cce56c63bb12a112086
```

#####master01ä¸Šæ£€æŸ¥

åœ¨dmaster01ä¸Šæ£€æŸ¥nodesåŠ å…¥æƒ…å†µ

```shell
$ kubectl get nodes
NAME              STATUS    ROLES     AGE       VERSION
devops-master01   Ready     master    19m       v1.9.3
devops-master02   Ready     master    4m        v1.9.3
devops-master03   Ready     master    4m        v1.9.3
```

#####åœ¨devops-master01ä¸Šæ£€æŸ¥é«˜å¯ç”¨çŠ¶æ€

```shell
$ kubectl get pods --all-namespaces -o wide 
NAMESPACE     NAME                                      READY     STATUS    RESTARTS   AGE       IP              NODE
kube-system   canal-cw8tw                               3/3       Running   4          3m        192.168.20.29   devops-master03
kube-system   canal-d54hs                               3/3       Running   3          5m        192.168.20.28   devops-master02
kube-system   canal-hpn82                               3/3       Running   5          17m       192.168.20.27   devops-master01
kube-system   heapster-65c5499476-zwgnh                 1/1       Running   1          8m        10.244.0.7      devops-master01
kube-system   kube-apiserver-devops-master01            1/1       Running   1          2m        192.168.20.27   devops-master01
kube-system   kube-apiserver-devops-master02            1/1       Running   0          11s       192.168.20.28   devops-master02
kube-system   kube-apiserver-devops-master03            1/1       Running   0          12s       192.168.20.29   devops-master03
kube-system   kube-controller-manager-devops-master01   1/1       Running   1          16m       192.168.20.27   devops-master01
kube-system   kube-controller-manager-devops-master02   1/1       Running   1          3m        192.168.20.28   devops-master02
kube-system   kube-controller-manager-devops-master03   1/1       Running   1          2m        192.168.20.29   devops-master03
kube-system   kube-dns-6f4fd4bdf-vwbk8                  3/3       Running   3          17m       10.244.0.2      devops-master01
kube-system   kube-proxy-59pwn                          1/1       Running   1          5m        192.168.20.28   devops-master02
kube-system   kube-proxy-jxt5s                          1/1       Running   1          3m        192.168.20.29   devops-master03
kube-system   kube-proxy-mr6l8                          1/1       Running   1          17m       192.168.20.27   devops-master01
kube-system   kube-scheduler-devops-master01            1/1       Running   1          16m       192.168.20.27   devops-master01
kube-system   kube-scheduler-devops-master02            1/1       Running   1          3m        192.168.20.28   devops-master02
kube-system   kube-scheduler-devops-master03            1/1       Running   1          2m        192.168.20.29   devops-master03
kube-system   kubernetes-dashboard-7c7bfdd855-2slp2     1/1       Running   1          15m       10.244.0.3      devops-master01
kube-system   monitoring-grafana-6774f65b56-mwdjv       1/1       Running   1          13m       10.244.0.4      devops-master01
kube-system   monitoring-influxdb-59d57d4d58-xmrxk      1/1       Running   1          13m       10.244.0.6      devops-master01
```

#####è®¾ç½®æ‰€æœ‰masterçš„scheduable

```shell
kubectl taint nodes --all node-role.kubernetes.io/master-
node "devops-master02" untainted
node "devops-master03" untainted
```

#####å¯¹åŸºç¡€ç»„ä»¶è¿›è¡Œå¤šèŠ‚ç‚¹scale

```shell
kubectl get deploy -n kube-system
NAME                   DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
heapster               1         1         1            1           3d
kube-dns               2         2         2            2           4d
kubernetes-dashboard   1         1         1            1           3d
monitoring-grafana     1         1         1            1           3d
monitoring-influxdb    1         1         1            1           3d

# dnsæ”¯æŒå¤šèŠ‚ç‚¹
kubectl scale --replicas=2 -n kube-system deployment/kube-dns
kubectl get pods --all-namespaces -o wide| grep kube-dns

```

---

[è¿”å›ç›®å½•](#ç›®å½•)

#### keepalivedå®‰è£…é…ç½®

#####åœ¨masterä¸Šé‡å¯keepalived

```shell
systemctl restart keepalived && systemctl status keepalived
$ ping 192.168.66.10
```

---

[è¿”å›ç›®å½•](#ç›®å½•)

#### nginxè´Ÿè½½å‡è¡¡é…ç½®

* åœ¨masterä¸Šå®‰è£…å¹¶å¯åŠ¨nginxä½œä¸ºè´Ÿè½½å‡è¡¡

```shell
docker-compose -f nginx-lb/docker-compose.yaml up -d
```

* åœ¨masterä¸ŠéªŒè¯è´Ÿè½½å‡è¡¡å’Œkeepalivedæ˜¯å¦æˆåŠŸ

```shell
curl -k https://192.168.66.10:16443
{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {
    
  },
  "status": "Failure",
  "message": "forbidden: User \"system:anonymous\" cannot get path \"/\"",
  "reason": "Forbidden",
  "details": {
    
  },
  "code": 403
}
```

---

[è¿”å›ç›®å½•](#ç›®å½•)

#### kube-proxyé…ç½®

- master01ä¸Šè®¾ç½®proxyé«˜å¯ç”¨ï¼Œè®¾ç½®serveræŒ‡å‘é«˜å¯ç”¨è™šæ‹ŸIPä»¥åŠè´Ÿè½½å‡è¡¡çš„16443ç«¯å£
```shell
$ kubectl edit -n kube-system configmap/kube-proxy
###ä¿®æ”¹ server: https://192.168.66.10:16443
```

- åœ¨masterä¸Šé‡å¯proxy

```shell
kubectl get pods --all-namespaces -o wide | grep proxy
kubectl delete pod -n kube-system kube-proxy-XXX

[root@master01 kubeadm-ha]# kubectl get pods --all-namespaces -o wide | grep proxy
kube-system   kube-proxy-n5hjz                        1/1       Running            0          4m        192.168.66.101   master02
kube-system   kube-proxy-pf2j9                        1/1       Running            0          4m        192.168.66.100   master01
kube-system   kube-proxy-r2xhb                        1/1       Running            0          14s       192.168.66.102   master03
```

---

[è¿”å›ç›®å½•](#ç›®å½•)

### nodeèŠ‚ç‚¹åŠ å…¥é«˜å¯ç”¨é›†ç¾¤è®¾ç½®

#### kubeadmåŠ å…¥é«˜å¯ç”¨é›†ç¾¤

- åœ¨æ‰€æœ‰workerèŠ‚ç‚¹ä¸Šè¿›è¡ŒåŠ å…¥kubernetesé›†ç¾¤æ“ä½œï¼Œè¿™é‡Œç»Ÿä¸€ä½¿ç”¨devops-master01çš„apiserveråœ°å€æ¥åŠ å…¥é›†ç¾¤ 

```shell
kubeadm join --token 7f276c.0741d82a5337f526 192.168.66.100:6443 --discovery-token-ca-cert-hash sha256:731e73e7a91afaac61b7f183cba840680b204ede71f30cce56c63bb12a112086
```

- åœ¨æ‰€æœ‰workerèŠ‚ç‚¹ä¸Šä¿®æ”¹kubernetesé›†ç¾¤è®¾ç½®ï¼Œæ›´æ”¹serverä¸ºé«˜å¯ç”¨è™šæ‹ŸIPä»¥åŠè´Ÿè½½å‡è¡¡çš„16443ç«¯å£

```shell
sed -i "s/192.168.66.100:6443/192.168.66.10:16443/g" /etc/kubernetes/bootstrap-kubelet.conf
sed -i "s/192.168.66.101:6443/192.168.66.10:16443/g" /etc/kubernetes/bootstrap-kubelet.conf
sed -i "s/192.168.66.102:6443/192.168.66.10:16443/g" /etc/kubernetes/bootstrap-kubelet.conf

sed -i "s/192.168.66.100:6443/192.168.66.10:16443/g" /etc/kubernetes/kubelet.conf
sed -i "s/192.168.66.101:6443/192.168.66.10:16443/g" /etc/kubernetes/kubelet.conf
sed -i "s/192.168.66.102:6443/192.168.66.10:16443/g" /etc/kubernetes/kubelet.conf

grep 192.168.66.10 /etc/kubernetes/*.conf 
/etc/kubernetes/bootstrap-kubelet.conf:    server: https://192.168.66.10:16443
/etc/kubernetes/kubelet.conf:    server: https://192.168.66.10:16443

$ systemctl restart docker kubelet
```


```shell
kubectl get nodes
NAME              STATUS    ROLES     AGE       VERSION
devops-master01   Ready     master    46m       v1.9.3
devops-master02   Ready     master    44m       v1.9.3
devops-master03   Ready     master    44m       v1.9.3
devops-node01     Ready     <none>    50s       v1.9.3
devops-node02     Ready     <none>    26s       v1.9.3
devops-node03     Ready     <none>    22s       v1.9.3
devops-node04     Ready     <none>    17s       v1.9.3
```

- è®¾ç½®workersçš„èŠ‚ç‚¹æ ‡ç­¾

```
kubectl label nodes devops-node01 role=worker
kubectl label nodes devops-node02 role=worker
kubectl label nodes devops-node03 role=worker
kubectl label nodes devops-node04 role=worker
```

#### éªŒè¯é›†ç¾¤é«˜å¯ç”¨è®¾ç½®

- NodePortæµ‹è¯•

```
# åˆ›å»ºä¸€ä¸ªreplicas=3çš„nginx deployment
$ kubectl run nginx --image=nginx --replicas=3 --port=80
deployment "nginx" created

# æ£€æŸ¥nginx podçš„åˆ›å»ºæƒ…å†µ
$ kubectl get pods -l=run=nginx -o wide
NAME                     READY     STATUS    RESTARTS   AGE       IP              NODE
nginx-6c7c8978f5-558kd   1/1       Running   0          9m        10.244.77.217   devops-node03
nginx-6c7c8978f5-ft2z5   1/1       Running   0          9m        10.244.172.67   devops-master01
nginx-6c7c8978f5-jr29b   1/1       Running   0          9m        10.244.85.165   devops-node04

# åˆ›å»ºnginxçš„NodePort service
$ kubectl expose deployment nginx --type=NodePort --port=80
service "nginx" exposed

# æ£€æŸ¥nginx serviceçš„åˆ›å»ºæƒ…å†µ
$ kubectl get svc -l=run=nginx -o wide
NAME      TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE       SELECTOR
nginx     NodePort   10.101.144.192   <none>        80:30847/TCP   10m       run=nginx

# æ£€æŸ¥nginx NodePort serviceæ˜¯å¦æ­£å¸¸æä¾›æœåŠ¡
$ curl devops-master01:30847
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
    body {
        width: 35em;
        margin: 0 auto;
        font-family: Tahoma, Verdana, Arial, sans-serif;
    }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>

$ kubectl delete deploy,svc nginx
```

- podä¹‹é—´äº’è®¿æµ‹è¯•

```
$ kubectl run nginx-server --image=nginx --port=80
$ kubectl expose deployment nginx-server --port=80
$ kubectl get pods -o wide -l=run=nginx-server
NAME                            READY     STATUS    RESTARTS   AGE       IP           NODE
nginx-server-6d64689779-lfcxc   1/1       Running   0          2m        10.244.5.7   devops-node03

$ kubectl run nginx-client -ti --rm --image=alpine -- ash
/ # wget nginx-server
Connecting to nginx-server (10.102.101.78:80)
index.html           100% |*****************************************|   612   0:00:00 ETA
/ # cat index.html 
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
    body {
        width: 35em;
        margin: 0 auto;
        font-family: Tahoma, Verdana, Arial, sans-serif;
    }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>


$ kubectl delete deploy,svc nginx-server
```

- è‡³æ­¤kubernetesé«˜å¯ç”¨é›†ç¾¤å®Œæˆéƒ¨ç½²ğŸ˜ƒ

